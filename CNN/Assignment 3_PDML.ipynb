{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializations\n",
    "import numpy as np\n",
    "#import cupy as np\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from os import listdir\n",
    "import cv2\n",
    "import random\n",
    "import copy\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in directory:daisy\n",
      "in directory:dandelion\n",
      "in directory:roses\n",
      "in directory:sunflowers\n",
      "in directory:tulips\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#shuffling the data\\n#np.random.seed(10)  \\ntesting_data,testing_labels=shuffle_in_unison(testing_data,testing_labels)\\ndaisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\\ndaisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\\ntraining_data,training_labels=shuffle_in_unison(training_data,training_labels)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all images in a directory\n",
    "#shuffle the labels and the data in Order\n",
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "    return a , b\n",
    "\n",
    "def load_directory(f_name):\n",
    "    #print (\"in file \" + f_name)\n",
    "    loaded_images = {}\n",
    "    labels_list = []\n",
    "    loaded_images_list = []\n",
    "    for filename in listdir('flower_photos/' + f_name):\n",
    "        # load image\n",
    "        img_data = plt.imread('flower_photos/' + f_name + '/' + filename)\n",
    "        new_img = cv2.resize(img_data,\n",
    "                             dsize=(32, 32),  # 32 x 32 images\n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        loaded_images[filename] = new_img\n",
    "        sorted_loaded_images = dict(\n",
    "            sorted(loaded_images.items(), key=lambda x: x[0].lower()))\n",
    "\n",
    "    for key in (sorted_loaded_images):\n",
    "        labels_list.append(f_name)\n",
    "        loaded_images_list.append(loaded_images[key])\n",
    "\n",
    "    ret = np.array(loaded_images_list)\n",
    "    labels = np.array(labels_list)\n",
    "    testing_batch = ret[-100:]\n",
    "    testing_batch_labels = labels[-100:]\n",
    "    validation_batch = ret[-200:-100]\n",
    "    validation_batch_labels = labels[-200:-100]\n",
    "    #plt.pyplot.figure()\n",
    "    #plt.pyplot.imshow(testing_batch[0])\n",
    "    # print (testing_batch.shape)\n",
    "    training_batch = ret[:-200].copy()\n",
    "    training_batch_labels = labels[:-200].copy()\n",
    "    #print(training_batch.shape)\n",
    "\n",
    "    return testing_batch, training_batch, testing_batch_labels, training_batch_labels, validation_batch,validation_batch_labels\n",
    "\n",
    "\n",
    "training_data = []\n",
    "testing_data = []\n",
    "training_labels = []\n",
    "testing_labels = []\n",
    "validation_data = []\n",
    "validation_labels=[]\n",
    "\n",
    "\n",
    "for directoryname in listdir('flower_photos'):\n",
    "    print('in directory:' + directoryname)\n",
    "    testing_batch, training_batch, testing_batch_labels, training_batch_labels,validation_batch,validation_batch_labels = load_directory(\n",
    "        directoryname)\n",
    "    testing_data.extend(testing_batch)\n",
    "    testing_labels.extend(testing_batch_labels)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(testing_batch[0])\n",
    "    training_data.extend(training_batch)\n",
    "    training_labels.extend(training_batch_labels)\n",
    "    \n",
    "    validation_data.extend(validation_batch)\n",
    "    validation_labels.extend(validation_batch_labels)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "testing_data = np.array(testing_data)\n",
    "#testing_data = np.reshape(testing_data , (testing_data.shape[0], -1))\n",
    "training_data = np.array(training_data)\n",
    "#training_data = np.reshape(training_data , (training_data.shape[0], -1))\n",
    "training_labels = np.array(training_labels)\n",
    "testing_labels = np.array(testing_labels)\n",
    "\n",
    "validation_labels = np.array(validation_labels)\n",
    "validation_data = np.array (validation_data)\n",
    "#validation_data = np.reshape(validation_data , (validation_data.shape[0], -1))\n",
    "\n",
    "#preprocess the data (zero centered and normalized)\n",
    "\n",
    "'''\n",
    "def load_flowers ():\n",
    "    return testing_data , training_data ,training_labels, testing_labels \n",
    "'''\n",
    "'''\n",
    "#shuffling the data\n",
    "#np.random.seed(10)  \n",
    "testing_data,testing_labels=shuffle_in_unison(testing_data,testing_labels)\n",
    "daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "training_data,training_labels=shuffle_in_unison(training_data,training_labels)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2670, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print ( training_data.shape)\n",
    "print ( testing_data.shape)\n",
    "print ( validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the data\n",
    "np.random.seed(10) \n",
    "\n",
    "daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "\n",
    "training_data,training_labels=shuffle_in_unison(training_data,training_labels)\n",
    "validation_data,validation_labels=shuffle_in_unison(validation_data,validation_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "#print (testing_labels)\n",
    "training_labels[training_labels == 'daisy'] = 0\n",
    "training_labels[training_labels == 'dandelion'] = 1\n",
    "training_labels[training_labels == 'roses'] = 2\n",
    "training_labels[training_labels == 'sunflowers'] = 3\n",
    "training_labels[training_labels == 'tulips'] = 4\n",
    "#print(training_labels[:500])\n",
    "#testing_labels = testing_labels.astype('int32')\n",
    "testing_labels[testing_labels == 'daisy'] = 0\n",
    "testing_labels[testing_labels == 'dandelion'] = 1\n",
    "testing_labels[testing_labels == 'roses'] = 2\n",
    "testing_labels[testing_labels == 'sunflowers'] = 3\n",
    "testing_labels[testing_labels == 'tulips'] = 4\n",
    "\n",
    "validation_labels[validation_labels == 'daisy'] = 0\n",
    "validation_labels[validation_labels == 'dandelion'] = 1\n",
    "validation_labels[validation_labels == 'roses'] = 2\n",
    "validation_labels[validation_labels == 'sunflowers'] = 3\n",
    "validation_labels[validation_labels == 'tulips'] = 4\n",
    "\n",
    "\n",
    "training_labels = training_labels.astype('int32')\n",
    "testing_labels = testing_labels.astype('int32')\n",
    "validation_labels = validation_labels.astype('int32')\n",
    "\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "#testing_data,testing_labels=shuffle_in_unison(testing_data,testing_labels)\n",
    "#print (daisy_lbls)\n",
    "print (testing_labels)\n",
    "print (training_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "print (daisy_lbls)\n",
    "#testing_data,testing_labels=shuffle_in_unison(testing_data,testing_labels) #this shuffles the splitted data , be careful !!\n",
    "print (daisy_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3)\n",
      "(2670, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n",
      "(2670,)\n",
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(testing_data.shape)\n",
    "print(training_data.shape)\n",
    "print(validation_data.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)\n",
    "print(validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 2 3 4 1 1 0 2 2 3 3 4 4 2 2 4 2 1 0 2 0 2 1 4 1 0 2 3 4 0 0 1 2 1 1\n",
      " 1 3 4 0 4 0 2 2 3 2 1 4 0 1 1 1 4 4 4 1 1 3 2 4 2 1 3 4 2 4 2 3 1 1 1 2 0\n",
      " 3 0 3 0 1 4 1 3 2 2 1 3 3 3 1 4 0 4 3 0 4 2 4 0 0 0 4 2 2 1 1 0 0 3 4 3 0\n",
      " 2 0 3 3 3 0 3 4 3 1 2 0 2 4 0 1 3 4 2 3 4 4 1 1 2 2 0 1 0 4 1 4 3 1 1 0 0\n",
      " 0 3 2 1 3 2 2 3 0 0 2 3 0 4 4 2 2 2 1 0 3 3 2 2 4 0 4 0 3 2 4 0 3 3 2 3 0\n",
      " 3 3 3 4 4 3 3 4 1 4 0 0 4 4 0 3 2 2 2 4 4 4 4 2 2 2 1 2 0 0 2 4 1 1 2 4 4\n",
      " 0 0 3 1 4 3 4 2 1 4 3 4 1 2 4 4 0 1 0 1 1 0 2 3 2 2 0 1 1 1 0 1 4 1 0 1 4\n",
      " 0 1 4 4 2 1 1 1 2 2 3 0 1 1 0 3 4 4 1 3 3 2 0 0 3 2 3 0 3 4 2 1 2 3 0 4 1\n",
      " 3 4 0 4 0 3 1 0 4 4 1 4 1 1 2 0 4 4 2 3 3 1 2 0 4 2 3 2 0 0 2 3 2 0 3 2 3\n",
      " 0 0 0 3 0 4 3 0 1 3 1 1 2 1 0 0 2 4 2 4 1 0 4 1 4 0 0 0 3 2 4 3 1 3 3 1 4\n",
      " 2 4 3 1 0 0 1 1 4 1 2 0 3 2 1 3 4 1 2 3 4 4 3 1 4 4 3 3 2 3 1 1 0 3 3 1 0\n",
      " 4 0 4 1 4 2 3 2 3 3 3 2 1 0 4 1 2 2 0 0 0 3 2 0 2 3 0 2 1 1 2 1 3 4 0 2 1\n",
      " 2 4 0 4 3 1 3 4 0 3 3 1 4 4 0 2 3 1 2 1 0 0 2 0 1 2 4 2 3 1 3 1 0 4 0 3 2\n",
      " 2 3 3 2 1 1 0 2 4 0 4 4 4 2 3 1 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers.py\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Layer(ABC):\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        \"\"\"\n",
    "        Returns weights tensor if layer is trainable.\n",
    "        Returns None for non-trainable layers.\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def gradients(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        \"\"\"\n",
    "        Returns bias tensor if layer is trainable.\n",
    "        Returns None for non-trainable layers.\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        Perform layer forward propagation logic.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        pass\n",
    "\n",
    "    def set_weights(self, w: np.array, b: np.array) -> None:\n",
    "        \"\"\"\n",
    "        Perform layer backward propagation logic.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Optimizer(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, layers: List[Layer]) -> None:\n",
    "        \"\"\"\n",
    "        Updates value of weights and bias tensors in trainable layers.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "class fullyConnected(Layer):\n",
    "\n",
    "    def __init__(self, w: np.array, b: np.array):\n",
    "        \"\"\"\n",
    "        :param w - 2D weights tensor with shape (units_curr, units_prev)\n",
    "        :param b - 1D bias tensor with shape (1, units_curr)\n",
    "        ------------------------------------------------------------------------\n",
    "        units_prev - number of units in previous layer\n",
    "        units_curr -  number of units in current layer\n",
    "        \"\"\"\n",
    "        self._w, self._b = w, b\n",
    "        self._dw, self._db = None, None\n",
    "        self._a_prev = None\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, units_prev: int, units_curr: int) -> fullyConnected:\n",
    "        \"\"\"\n",
    "        :param units_prev - positive integer, number of units in previous layer\n",
    "        :param units_curr - positive integer, number of units in current layer\n",
    "        \"\"\"\n",
    "        w = np.random.randn(units_curr, units_prev) * 0.1\n",
    "        b = np.random.randn(1, units_curr) * 0.1\n",
    "        return cls(w=w, b=b)\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        return self._w, self._b\n",
    "\n",
    "    @property\n",
    "    def gradients(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        if self._dw is None or self._db is None:\n",
    "            return None\n",
    "        return self._dw, self._db\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 2D tensor with shape (n, units_prev)\n",
    "        :output - 2D tensor with shape (n, units_curr)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        units_prev - number of units in previous layer\n",
    "        units_curr -  number of units in current layer\n",
    "        \"\"\"\n",
    "        self._a_prev = np.array(a_prev, copy=True)\n",
    "        return np.dot(a_prev, self._w.T) + self._b\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 2D tensor with shape (n, units_curr)\n",
    "        :output - 2D tensor with shape (n, units_prev)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        units_prev - number of units in previous layer\n",
    "        units_curr -  number of units in current layer\n",
    "        \"\"\"\n",
    "        n = self._a_prev.shape[0]\n",
    "        self._dw = np.dot(da_curr.T, self._a_prev) / n\n",
    "        self._db = np.sum(da_curr, axis=0, keepdims=True) / n\n",
    "        return np.dot(da_curr, self._w)\n",
    "\n",
    "    def set_weights(self, w: np.array, b: np.array) -> None:\n",
    "        \"\"\"\n",
    "        :param w - 2D weights tensor with shape (units_curr, units_prev)\n",
    "        :param b - 1D bias tensor with shape (1, units_curr)\n",
    "        ------------------------------------------------------------------------\n",
    "        units_prev - number of units in previous layer\n",
    "        units_curr -  number of units in current layer\n",
    "        \"\"\"\n",
    "        self._w = w\n",
    "        self._b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(Layer):\n",
    "\n",
    "    def __init__(\n",
    "        self, w: np.array,\n",
    "        b: np.array,\n",
    "        padding: str = 'valid',\n",
    "        stride: int = 1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param w -  4D tensor with shape (h_f, w_f, c_f, n_f)\n",
    "        :param b - 1D tensor with shape (n_f, )\n",
    "        :param padding - flag describing type of activation padding valid/same\n",
    "        :param stride - stride along width and height of input volume\n",
    "        ------------------------------------------------------------------------\n",
    "        h_f - height of filter volume\n",
    "        w_f - width of filter volume\n",
    "        c_f - number of channels of filter volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        self._w, self._b = w, b\n",
    "        self._padding = padding\n",
    "        self._stride = stride\n",
    "        self._dw, self._db = None, None\n",
    "        self._a_prev = None\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(\n",
    "        cls, filters: int,\n",
    "        kernel_shape: Tuple[int, int, int],\n",
    "        padding: str = 'valid',\n",
    "        stride: int = 1\n",
    "    ) -> Convolution:\n",
    "        w = np.random.randn(*kernel_shape, filters) * 0.1\n",
    "        b = np.random.randn(filters) * 0.1\n",
    "        return cls(w=w, b=b, padding=padding, stride=stride)\n",
    "\n",
    "    @property\n",
    "    def weights(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        return self._w, self._b\n",
    "\n",
    "    @property\n",
    "    def gradients(self) -> Optional[Tuple[np.array, np.array]]:\n",
    "        if self._dw is None or self._db is None:\n",
    "            return None\n",
    "        return self._dw, self._db\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 4D tensor with shape (n, h_in, w_in, c)\n",
    "        :output 4D tensor with shape (n, h_out, w_out, n_f)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        self._a_prev = np.array(a_prev, copy=True)\n",
    "        output_shape = self.calculate_output_dims(input_dims=a_prev.shape)\n",
    "        n, h_in, w_in, _ = a_prev.shape\n",
    "        _, h_out, w_out, _ = output_shape\n",
    "        h_f, w_f, _, n_f = self._w.shape\n",
    "        pad = self.calculate_pad_dims()\n",
    "        a_prev_pad = self.pad(array=a_prev, pad=pad)\n",
    "        output = np.zeros(output_shape)\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_f\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_f\n",
    "\n",
    "                output[:, i, j, :] = np.sum(\n",
    "                    a_prev_pad[:, h_start:h_end, w_start:w_end, :, np.newaxis] *\n",
    "                    self._w[np.newaxis, :, :, :],\n",
    "                    axis=(1, 2, 3)\n",
    "                )\n",
    "\n",
    "        return output + self._b\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 4D tensor with shape (n, h_out, w_out, n_f)\n",
    "        :output 4D tensor with shape (n, h_in, w_in, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        _, h_out, w_out, _ = da_curr.shape\n",
    "        n, h_in, w_in, _ = self._a_prev.shape\n",
    "        h_f, w_f, _, _ = self._w.shape\n",
    "        pad = self.calculate_pad_dims()\n",
    "        a_prev_pad = self.pad(array=self._a_prev, pad=pad)\n",
    "        output = np.zeros_like(a_prev_pad)\n",
    "\n",
    "        self._db = da_curr.sum(axis=(0, 1, 2)) / n\n",
    "        self._dw = np.zeros_like(self._w)\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_f\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_f\n",
    "                output[:, h_start:h_end, w_start:w_end, :] += np.sum(\n",
    "                    self._w[np.newaxis, :, :, :, :] *\n",
    "                    da_curr[:, i:i+1, j:j+1, np.newaxis, :],\n",
    "                    axis=4\n",
    "                )\n",
    "                self._dw += np.sum(\n",
    "                    a_prev_pad[:, h_start:h_end, w_start:w_end, :, np.newaxis] *\n",
    "                    da_curr[:, i:i+1, j:j+1, np.newaxis, :],\n",
    "                    axis=0\n",
    "                )\n",
    "\n",
    "        self._dw /= n\n",
    "        return output[:, pad[0]:pad[0]+h_in, pad[1]:pad[1]+w_in, :]\n",
    "\n",
    "    def set_weights(self, w: np.array, b: np.array) -> None:\n",
    "        \"\"\"\n",
    "        :param w -  4D tensor with shape (h_f, w_f, c_f, n_f)\n",
    "        :param b - 1D tensor with shape (n_f, )\n",
    "        ------------------------------------------------------------------------\n",
    "        h_f - height of filter volume\n",
    "        w_f - width of filter volume\n",
    "        c_f - number of channels of filter volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        self._w = w\n",
    "        self._b = b\n",
    "\n",
    "    def calculate_output_dims(\n",
    "        self, input_dims: Tuple[int, int, int, int]\n",
    "    ) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"\n",
    "        :param input_dims - 4 element tuple (n, h_in, w_in, c)\n",
    "        :output 4 element tuple (n, h_out, w_out, n_f)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        n, h_in, w_in, _ = input_dims\n",
    "        h_f, w_f, _, n_f = self._w.shape\n",
    "        if self._padding == 'same':\n",
    "            return n, h_in, w_in, n_f\n",
    "        elif self._padding == 'valid':\n",
    "            h_out = (h_in - h_f) // self._stride + 1\n",
    "            w_out = (w_in - w_f) // self._stride + 1\n",
    "            return n, h_out, w_out, n_f\n",
    "\n",
    "    def calculate_pad_dims(self) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        :output - 2 element tuple (h_pad, w_pad)\n",
    "        ------------------------------------------------------------------------\n",
    "        h_pad - single side padding on height of the volume\n",
    "        w_pad - single side padding on width of the volume\n",
    "        \"\"\"\n",
    "        if self._padding == 'same':\n",
    "            h_f, w_f, _, _ = self._w.shape\n",
    "            return (h_f - 1) // 2, (w_f - 1) // 2\n",
    "        elif self._padding == 'valid':\n",
    "            return 0, 0\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(array: np.array, pad: Tuple[int, int]) -> np.array:\n",
    "        \"\"\"\n",
    "        :param array -  4D tensor with shape (n, h_in, w_in, c)\n",
    "        :param pad - 2 element tuple (h_pad, w_pad)\n",
    "        :output 4D tensor with shape (n, h_out, w_out, n_f)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        h_pad - single side padding on height of the volume\n",
    "        w_pad - single side padding on width of the volume\n",
    "        \"\"\"\n",
    "        return np.pad(\n",
    "            array=array,\n",
    "            pad_width=((0, 0), (pad[0], pad[0]), (pad[1], pad[1]), (0, 0)),\n",
    "            mode='constant'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im2col_idx(\n",
    "    array_shape: Tuple[int, int, int, int],\n",
    "    filter_dim: Tuple[int, int] = (3, 3),\n",
    "    pad: int = 0,\n",
    "    stride: int = 1\n",
    ") -> Tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    :param array_shape - 4 element tuple (n, c, h_in, w_in)\n",
    "    :param filter_dim - 2 element tuple (h_f, w_f)\n",
    "    :param pad - padding along width and height of input volume\n",
    "    :param stride - stride along width and height of input volume\n",
    "    :output 2D tensor\n",
    "    ------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    w_in - width of input volume\n",
    "    h_in - width of input volume\n",
    "    c - number of channels of the input volume\n",
    "    \"\"\"\n",
    "    n, c, h_in, w_in = array_shape\n",
    "    h_f, w_f = filter_dim\n",
    "\n",
    "    h_out = (h_in + 2 * pad - h_f) // stride + 1\n",
    "    w_out = (w_in + 2 * pad - w_f) // stride + 1\n",
    "\n",
    "    i0 = np.repeat(np.arange(h_f), w_f)\n",
    "    i0 = np.tile(i0, c)\n",
    "    i1 = stride * np.repeat(np.arange(h_out), w_out)\n",
    "    j0 = np.tile(np.arange(w_f), h_f * c)\n",
    "    j1 = stride * np.tile(np.arange(w_out), h_out)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "    k = np.repeat(np.arange(c), h_f * w_f).reshape(-1, 1)\n",
    "    return k, i, j\n",
    "\n",
    "\n",
    "def im2col(\n",
    "    array: np.array,\n",
    "    filter_dim: Tuple[int, int] = (3, 3),\n",
    "    pad: int = 0,\n",
    "    stride: int = 1\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    :param array - 4D tensor with shape (n, c, h_in, w_in)\n",
    "    :param filter_dim - 2 element tuple (h_f, w_f)\n",
    "    :param pad - padding along width and height of input volume\n",
    "    :param stride - stride along width and height of input volume\n",
    "    :output 2D tensor with shape (h_f * w_f * c, h_out, w_out * n)\n",
    "    ------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    w_in - width of input volume\n",
    "    h_in - width of input volume\n",
    "    w_in - width of output volume\n",
    "    h_in - width of output volume\n",
    "    w_f - width of filter volume\n",
    "    h_f - height of filter volume\n",
    "    c - number of channels of the input volume\n",
    "    \"\"\"\n",
    "    _, c, _, _ = array.shape\n",
    "    h_f, w_f = filter_dim\n",
    "    array_pad = np.pad(\n",
    "        array=array,\n",
    "        pad_width=((0, 0), (0, 0), (pad, pad), (pad, pad)),\n",
    "        mode='constant'\n",
    "    )\n",
    "    k, i, j = get_im2col_idx(\n",
    "        array_shape=array.shape,\n",
    "        filter_dim=filter_dim,\n",
    "        pad=pad,\n",
    "        stride=stride\n",
    "    )\n",
    "    cols = array_pad[:, k, i, j]\n",
    "    return cols.transpose(1, 2, 0).reshape(h_f * w_f * c, -1)\n",
    "\n",
    "\n",
    "def col2im(\n",
    "    cols: np.array,\n",
    "    array_shape: Tuple[int, int, int, int],\n",
    "    filter_dim: Tuple[int, int] = (3, 3),\n",
    "    pad: int = 0,\n",
    "    stride: int = 1\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    :param cols - 2D tensor with shape (h_f * w_f * c, h_out, w_out * n)\n",
    "    :param array_shape - 4 element tuple (n, c, h_in, w_in)\n",
    "    :param filter_dim - 2 element tuple (h_f, w_f)\n",
    "    :param pad - padding along width and height of input volume\n",
    "    :param stride - stride along width and height of input volume\n",
    "    :output 4D tensor with shape (n, c, h_in, w_in)\n",
    "    ------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    w_in - width of input volume\n",
    "    h_in - width of input volume\n",
    "    w_in - width of output volume\n",
    "    h_in - width of output volume\n",
    "    w_f - width of filter volume\n",
    "    h_f - height of filter volume\n",
    "    c - number of channels of the input volume\n",
    "    \"\"\"\n",
    "    n, c, h_in, w_in = array_shape\n",
    "    h_f, w_f = filter_dim\n",
    "    h_pad, w_pad = h_in + 2 * pad, w_in + 2 * pad\n",
    "    array_pad = np.zeros((n, c, h_pad, w_pad), dtype=cols.dtype)\n",
    "    k, i, j = get_im2col_idx(\n",
    "        array_shape=array_shape,\n",
    "        filter_dim=filter_dim,\n",
    "        pad=pad,\n",
    "        stride=stride\n",
    "    )\n",
    "    cols_reshaped = cols.reshape(c * h_f * w_f, -1, n)\n",
    "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
    "    np.add.at(array_pad, (slice(None), k, i, j), cols_reshaped)\n",
    "    return array_pad[:, :, pad:pad+h_in, pad:pad+w_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastConvolution(Convolution):\n",
    "\n",
    "    def __init__(\n",
    "        self, w: np.array,\n",
    "        b: np.array,\n",
    "        padding: str = 'valid',\n",
    "        stride: int = 1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param w -  4D tensor with shape (h_f, w_f, c_f, n_f)\n",
    "        :param b - 1D tensor with shape (n_f, )\n",
    "        :param padding - flag describing type of activation padding valid/same\n",
    "        :param stride - stride along width and height of input volume\n",
    "        ------------------------------------------------------------------------\n",
    "        h_f - height of filter volume\n",
    "        w_f - width of filter volume\n",
    "        c_f - number of channels of filter volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        super(fastConvolution, self).__init__(\n",
    "            w=w, b=b, padding=padding, stride=stride\n",
    "        )\n",
    "        self._cols = None\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 4D tensor with shape (n, h_in, w_in, c)\n",
    "        :output 4D tensor with shape (n, h_out, w_out, n_f)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        self._a_prev = np.array(a_prev, copy=True)\n",
    "        n, h_out, w_out, _ = self.calculate_output_dims(input_dims=a_prev.shape)\n",
    "        h_f, w_f, _, n_f = self._w.shape\n",
    "        pad = self.calculate_pad_dims()\n",
    "        w = np.transpose(self._w, (3, 2, 0, 1))\n",
    "\n",
    "        self._cols = im2col(\n",
    "            array=np.moveaxis(a_prev, -1, 1),\n",
    "            filter_dim=(h_f, w_f),\n",
    "            pad=pad[0],\n",
    "            stride=self._stride\n",
    "        )\n",
    "\n",
    "        result = w.reshape((n_f, -1)).dot(self._cols)\n",
    "        output = result.reshape(n_f, h_out, w_out, n)\n",
    "\n",
    "        return output.transpose(3, 1, 2, 0) + self._b\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 4D tensor with shape (n, h_out, w_out, n_f)\n",
    "        :output 4D tensor with shape (n, h_in, w_in, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        w_out - width of input volume\n",
    "        h_out - width of input volume\n",
    "        c - number of channels of the input volume\n",
    "        n_f - number of filters in filter volume\n",
    "        \"\"\"\n",
    "        n, h_out, w_out, _ = self.calculate_output_dims(\n",
    "            input_dims=self._a_prev.shape)\n",
    "        h_f, w_f, _, n_f = self._w.shape\n",
    "        pad = self.calculate_pad_dims()\n",
    "\n",
    "        self._db = da_curr.sum(axis=(0, 1, 2)) / n\n",
    "        da_curr_reshaped = da_curr.transpose(3, 1, 2, 0).reshape(n_f, -1)\n",
    "\n",
    "        w = np.transpose(self._w, (3, 2, 0, 1))\n",
    "        dw = da_curr_reshaped.dot(self._cols.T).reshape(w.shape)\n",
    "        self._dw = np.transpose(dw, (2, 3, 1, 0))\n",
    "\n",
    "        output_cols = w.reshape(n_f, -1).T.dot(da_curr_reshaped)\n",
    "\n",
    "        output = col2im(\n",
    "            cols=output_cols,\n",
    "            array_shape=np.moveaxis(self._a_prev, -1, 1).shape,\n",
    "            filter_dim=(h_f, w_f),\n",
    "            pad=pad[0],\n",
    "            stride=self._stride\n",
    "        )\n",
    "        return np.transpose(output, (0, 2, 3, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer(Layer):\n",
    "\n",
    "    def __init__(self, pool_size: Tuple[int, int], stride: int = 2):\n",
    "        \"\"\"\n",
    "        :param pool_size - tuple holding shape of 2D pooling window\n",
    "        :param stride - stride along width and height of input volume used to\n",
    "        apply pooling operation\n",
    "        \"\"\"\n",
    "        self._pool_size = pool_size\n",
    "        self._stride = stride\n",
    "        self._a = None\n",
    "        self._cache = {}\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 4D tensor with shape(n, h_in, w_in, c)\n",
    "        :output 4D tensor with shape(n, h_out, w_out, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        c - number of channels of the input/output volume\n",
    "        w_out - width of output volume\n",
    "        h_out - width of output volume\n",
    "        \"\"\"\n",
    "        self._a = np.array(a_prev, copy=True)\n",
    "        n, h_in, w_in, c = a_prev.shape\n",
    "        h_pool, w_pool = self._pool_size\n",
    "        h_out = 1 + (h_in - h_pool) // self._stride\n",
    "        w_out = 1 + (w_in - w_pool) // self._stride\n",
    "        output = np.zeros((n, h_out, w_out, c))\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_pool\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_pool\n",
    "                a_prev_slice = a_prev[:, h_start:h_end, w_start:w_end, :]\n",
    "                self._save_mask(x=a_prev_slice, cords=(i, j))\n",
    "                output[:, i, j, :] = np.max(a_prev_slice, axis=(1, 2))\n",
    "        return output\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 4D tensor with shape(n, h_out, w_out, c)\n",
    "        :output 4D tensor with shape(n, h_in, w_in, c)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        w_in - width of input volume\n",
    "        h_in - width of input volume\n",
    "        c - number of channels of the input/output volume\n",
    "        w_out - width of output volume\n",
    "        h_out - width of output volume\n",
    "        \"\"\"\n",
    "        output = np.zeros_like(self._a)\n",
    "        _, h_out, w_out, _ = da_curr.shape\n",
    "        h_pool, w_pool = self._pool_size\n",
    "\n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                h_start = i * self._stride\n",
    "                h_end = h_start + h_pool\n",
    "                w_start = j * self._stride\n",
    "                w_end = w_start + w_pool\n",
    "                output[:, h_start:h_end, w_start:w_end, :] += \\\n",
    "                    da_curr[:, i:i + 1, j:j + 1, :] * self._cache[(i, j)]\n",
    "        return output\n",
    "\n",
    "    def _save_mask(self, x: np.array, cords: Tuple[int, int]) -> None:\n",
    "        mask = np.zeros_like(x)\n",
    "        n, h, w, c = x.shape\n",
    "        x = x.reshape(n, h * w, c)\n",
    "        idx = np.argmax(x, axis=1)\n",
    "\n",
    "        n_idx, c_idx = np.indices((n, c))\n",
    "        mask.reshape(n, h * w, c)[n_idx, idx, c_idx] = 1\n",
    "        self._cache[cords] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._shape = ()\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - ND tensor with shape (n, ..., channels)\n",
    "        :output - 1D tensor with shape (n, 1)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        \"\"\"\n",
    "        self._shape = a_prev.shape\n",
    "        return np.ravel(a_prev).reshape(a_prev.shape[0], -1)\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 1D tensor with shape (n, 1)\n",
    "        :output - ND tensor with shape (n, ..., channels)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        \"\"\"\n",
    "        return da_curr.reshape(self._shape)\n",
    "    \n",
    "    \n",
    "class DropoutLayer(Layer):\n",
    "\n",
    "    def __init__(self, keep_prob):\n",
    "        \"\"\"\n",
    "        :param keep_prob - probability that given unit will not be dropped out\n",
    "        \"\"\"\n",
    "        self._keep_prob = keep_prob\n",
    "        self._mask = None\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        if training:\n",
    "            self._mask = (np.random.rand(*a_prev.shape) < self._keep_prob)\n",
    "            return self._apply_mask(a_prev, self._mask)\n",
    "        else:\n",
    "            return a_prev\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        return self._apply_mask(da_curr, self._mask)\n",
    "\n",
    "    def _apply_mask(self, array: np.array, mask: np.array) -> np.array:\n",
    "        array *= mask\n",
    "        array /= self._keep_prob\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activations.py\n",
    "\n",
    "class ReluLayer(Layer):\n",
    "    def __init__(self):\n",
    "        self._z = None\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - ND tensor with shape (n, ..., channels)\n",
    "        :output ND tensor with shape (n, ..., channels)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        \"\"\"\n",
    "        self._z = np.maximum(0, a_prev)\n",
    "        return self._z\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - ND tensor with shape (n, ..., channels)\n",
    "        :output ND tensor with shape (n, ..., channels)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        \"\"\"\n",
    "        dz = np.array(da_curr, copy=True)\n",
    "        dz[self._z <= 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer(Layer):\n",
    "    def __init__(self):\n",
    "        self._z = None\n",
    "\n",
    "    def forward_pass(self, a_prev: np.array, training: bool) -> np.array:\n",
    "        \"\"\"\n",
    "        :param a_prev - 2D tensor with shape (n, k)\n",
    "        :output 2D tensor with shape (n, k)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        k - number of classes\n",
    "        \"\"\"\n",
    "        e = np.exp(a_prev - a_prev.max(axis=1, keepdims=True))\n",
    "        self._z = e / np.sum(e, axis=1, keepdims=True)\n",
    "        return self._z\n",
    "\n",
    "    def backward_pass(self, da_curr: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param da_curr - 2D tensor with shape (n, k)\n",
    "        :output 2D tensor with shape (n, k)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in batch\n",
    "        k - number of classes\n",
    "        \"\"\"\n",
    "        return da_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py for preprocessing the data and calculating the accuracy\n",
    "import time\n",
    "def convert_categorical2one_hot(y: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    :param y - categorical array with (n, 1) shape\n",
    "    :return one hot array with (n, k) shape\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    one_hot_matrix = np.zeros((y.size, y.max() + 1))\n",
    "    one_hot_matrix[np.arange(y.size), y] = 1\n",
    "    return one_hot_matrix\n",
    "\n",
    "\n",
    "def convert_prob2categorical(probs: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    :param probs - softmax output array with (n, k) shape\n",
    "    :return categorical array with (n, ) shape\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    return np.argmax(probs, axis=1)\n",
    "\n",
    "\n",
    "def convert_prob2one_hot(probs: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    :param probs - softmax output array with (n, k) shape\n",
    "    :return one hot array with (n, k) shape\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    class_idx = convert_prob2categorical(probs)\n",
    "    one_hot_matrix = np.zeros_like(probs)\n",
    "    one_hot_matrix[np.arange(probs.shape[0]), class_idx] = 1\n",
    "    return one_hot_matrix\n",
    "\n",
    "\n",
    "def generate_batches(x: np.array, y: np.array, batch_size: int):\n",
    "    \"\"\"\n",
    "    :param x - features array with (n, ...) shape\n",
    "    :param y - one hot ground truth array with (n, k) shape\n",
    "    :batch_size - number of elements in single batch\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples in data set\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    for i in range(0, x.shape[0], batch_size):\n",
    "        yield (\n",
    "            x.take(indices=range(\n",
    "                i, min(i + batch_size, x.shape[0])), axis=0),\n",
    "            y.take(indices=range(\n",
    "                i, min(i + batch_size, y.shape[0])), axis=0)\n",
    "        )\n",
    "        \n",
    "def format_time(start_time: time.time, end_time: time.time) -> str:\n",
    "    \"\"\"\n",
    "    :param start_time - beginning of time period\n",
    "    :param end_time - ending of time period\n",
    "    :output - string in HH:MM:SS.ss format\n",
    "    ----------------------------------------------------------------------------\n",
    "    HH - hours\n",
    "    MM - minutes\n",
    "    SS - seconds\n",
    "    ss - hundredths of a second\n",
    "    \"\"\"\n",
    "    hours, rem = divmod(end_time - start_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(minutes), seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_accuracy(y_hat: np.array, y: np.array) -> float:\n",
    "    \"\"\"\n",
    "    :param y_hat - 2D one-hot prediction tensor with shape (n, k)\n",
    "    :param y - 2D one-hot ground truth labels tensor with shape (n, k)\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    y_hat = convert_prob2one_hot(y_hat)\n",
    "    return (y_hat == y).all(axis=1).mean()\n",
    "\n",
    "\n",
    "def softmax_cross_entropy(y_hat, y, eps=1e-20) -> float:\n",
    "    \"\"\"\n",
    "    :param y_hat - 2D one-hot prediction tensor with shape (n, k)\n",
    "    :param y - 2D one-hot ground truth labels tensor with shape (n, k)\n",
    "    ----------------------------------------------------------------------------\n",
    "    n - number of examples in batch\n",
    "    k - number of classes\n",
    "    \"\"\"\n",
    "    n = y_hat.shape[0]\n",
    "    return - np.sum(y * np.log(np.clip(y_hat, eps, 1.))) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent flavors\n",
    "class Adam(Optimizer):\n",
    "    def __init__(\n",
    "        self, lr: float,\n",
    "        beta1: float = 0.9,\n",
    "        beta2: float = 0.999,\n",
    "        eps: float = 1e-8\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param lr - learning rate\n",
    "        :param beta1 -\n",
    "        :param beta2 -\n",
    "        :param eps - small value to avoid zero denominator\n",
    "        \"\"\"\n",
    "        self._cache_v = {}\n",
    "        self._cache_s = {}\n",
    "        self._lr = lr\n",
    "        self._beta1 = beta1\n",
    "        self._beta2 = beta2\n",
    "        self._eps = eps\n",
    "\n",
    "    def update(self, layers: List[Layer]) -> None:\n",
    "        if len(self._cache_s) == 0 or len(self._cache_v) == 0:\n",
    "            self._init_cache(layers)\n",
    "\n",
    "        for idx, layer in enumerate(layers):\n",
    "            weights, gradients = layer.weights, layer.gradients\n",
    "            if weights is None or gradients is None:\n",
    "                continue\n",
    "\n",
    "            (w, b), (dw, db) = weights, gradients\n",
    "            dw_key, db_key = Adam._get_cache_keys(idx)\n",
    "\n",
    "            self._cache_v[dw_key] = self._beta1 * self._cache_v[dw_key] + \\\n",
    "                (1 - self._beta1) * dw\n",
    "            self._cache_v[db_key] = self._beta1 * self._cache_v[db_key] + \\\n",
    "                (1 - self._beta1) * db\n",
    "\n",
    "            self._cache_s[dw_key] = self._beta2 * self._cache_s[dw_key] + \\\n",
    "                (1 - self._beta2) * np.square(dw)\n",
    "            self._cache_s[db_key] = self._beta2 * self._cache_s[db_key] + \\\n",
    "                (1 - self._beta2) * np.square(db)\n",
    "\n",
    "            dw = self._cache_v[dw_key] / (np.sqrt(self._cache_s[dw_key]) + self._eps)\n",
    "            db = self._cache_v[db_key] / (np.sqrt(self._cache_s[db_key]) + self._eps)\n",
    "\n",
    "            layer.set_weights(\n",
    "                w=w - self._lr * dw,\n",
    "                b=b - self._lr * db\n",
    "            )\n",
    "\n",
    "    def _init_cache(self, layers: List[Layer]) -> None:\n",
    "        for idx, layer in enumerate(layers):\n",
    "            gradients = layer.gradients\n",
    "            if gradients is None:\n",
    "                continue\n",
    "\n",
    "            dw, db = gradients\n",
    "            dw_key, db_key = Adam._get_cache_keys(idx)\n",
    "\n",
    "            self._cache_v[dw_key] = np.zeros_like(dw)\n",
    "            self._cache_v[db_key] = np.zeros_like(db)\n",
    "            self._cache_s[dw_key] = np.zeros_like(dw)\n",
    "            self._cache_s[db_key] = np.zeros_like(db)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_cache_keys(idx: int) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        :param idx - index of layer\n",
    "        \"\"\"\n",
    "        return f\"dw{idx}\", f\"db{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, lr: float):\n",
    "        \"\"\"\n",
    "        :param lr - learning rate\n",
    "        \"\"\"\n",
    "        self._lr = lr\n",
    "\n",
    "    def update(self, layers: List[Layer]) -> None:\n",
    "        for layer in layers:\n",
    "            weights, gradients = layer.weights, layer.gradients\n",
    "            if weights is None or gradients is None:\n",
    "                continue\n",
    "\n",
    "            (w, b), (dw, db) = weights, gradients\n",
    "            layer.set_weights(\n",
    "                w = w - self._lr * dw,\n",
    "                b = b - self._lr * db\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2670, 32, 32, 3)\n",
      "y_train shape: (2670, 5)\n",
      "X_test shape: (500, 32, 32, 3)\n",
      "y_test shape: (500, 5)\n",
      "X_valid shape: (500, 32, 32, 3)\n",
      "y_valid shape: (500, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = training_data / 255\n",
    "training_labels = convert_categorical2one_hot(training_labels)\n",
    "testing_data = testing_data / 255\n",
    "testing_labels = convert_categorical2one_hot(testing_labels)\n",
    "validation_data = validation_data / 255\n",
    "validation_labels = convert_categorical2one_hot(validation_labels)\n",
    "print(\"X_train shape:\", training_data.shape)\n",
    "print(\"y_train shape:\", training_labels.shape)\n",
    "print(\"X_test shape:\", testing_data.shape)\n",
    "print(\"y_test shape:\", testing_labels.shape)\n",
    "print(\"X_valid shape:\", validation_data.shape)\n",
    "print(\"y_valid shape:\", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Dict, Callable, Optional\n",
    "import time\n",
    "\n",
    "class SequentialModel:\n",
    "    def __init__(self, layers: List[Layer], optimizer: Optimizer):\n",
    "        self._layers = layers\n",
    "        self._optimizer = optimizer\n",
    "\n",
    "        self._train_acc = []\n",
    "        self._test_acc = []\n",
    "        self._train_loss = []\n",
    "        self._test_loss = []\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        x_train: np.array,\n",
    "        y_train: np.array,\n",
    "        x_test: np.array,\n",
    "        y_test: np.array,\n",
    "        epochs: int,\n",
    "        bs: int = 64,\n",
    "        verbose: bool = False,\n",
    "        callback: Optional[Callable[[SequentialModel], None]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        :param x_train - ND feature tensor with shape (n_train, ...)\n",
    "        :param y_train - 2D one-hot labels tensor with shape (n_train, k)\n",
    "        :param x_test - ND feature tensor with shape (n_test, ...)\n",
    "        :param y_test - 2D one-hot labels tensor with shape (n_test, k)\n",
    "        :param epochs - number of epochs used during model training\n",
    "        :param bs - size of batch used during model training\n",
    "        :param verbose - if set to True, model will produce logs during training\n",
    "        :param callback - function that will be executed at the end of each epoch\n",
    "        ------------------------------------------------------------------------\n",
    "        n_train - number of examples in train data set\n",
    "        n_test - number of examples in test data set\n",
    "        k - number of classes\n",
    "        \"\"\"\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            y_hat = np.zeros_like(y_train)\n",
    "            for idx, (x_batch, y_batch) in \\\n",
    "                    enumerate(generate_batches(x_train, y_train, bs)):\n",
    "\n",
    "                y_hat_batch = self._forward(x_batch, training=True)\n",
    "                activation = y_hat_batch - y_batch\n",
    "                self._backward(activation)\n",
    "                self._update()\n",
    "                n_start = idx * bs\n",
    "                n_end = n_start + y_hat_batch.shape[0]\n",
    "                y_hat[n_start:n_end, :] = y_hat_batch\n",
    "            #print(\"beeeb\") #reemove\n",
    "            train_acc = softmax_accuracy(y_hat, y_train)\n",
    "            train_loss = softmax_cross_entropy(y_hat, y_train)\n",
    "            self._train_acc.append(train_acc)\n",
    "            self._train_loss.append(train_loss)\n",
    "\n",
    "            y_hat = self._forward(x_test, training=False)\n",
    "            test_acc = softmax_accuracy(y_hat, y_test)\n",
    "            self._test_acc.append(test_acc)\n",
    "            test_loss = softmax_cross_entropy(y_hat, y_test)\n",
    "            self._test_loss.append(test_loss)\n",
    "\n",
    "            if verbose:\n",
    "                epoch_time = format_time(start_time=epoch_start, end_time=time.time())\n",
    "                print(\"epoch: {:05} | tr_loss: {:.5f} | tr_acc: {:.5f} | val_loss: {:.5f} | val_acc: {:.5f} | time: {}\"\n",
    "                      .format(epoch+1,train_loss ,train_acc ,test_loss, test_acc, epoch_time))\n",
    "\n",
    "    def predict(self, x: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        :param x - ND feature tensor with shape (n, ...)\n",
    "        :output 2D one-hot labels tensor with shape (n, k)\n",
    "        ------------------------------------------------------------------------\n",
    "        n - number of examples in data set\n",
    "        k - number of classes\n",
    "        \"\"\"\n",
    "        return self._forward(x, training=False)\n",
    "\n",
    "    @property\n",
    "    def history(self) -> Dict[str, List[float]]:\n",
    "        return {\n",
    "            \"train_acc\": self._train_acc,\n",
    "            \"test_acc\": self._test_acc,\n",
    "            \"train_loss\": self._train_loss,\n",
    "            \"test_loss\": self._test_loss\n",
    "        }\n",
    "\n",
    "    def _forward(self, x: np.array, training: bool) -> np.array:\n",
    "        activation = x\n",
    "        for idx, layer in enumerate(self._layers):\n",
    "            activation = layer.forward_pass(a_prev=activation, training=training)\n",
    "        return activation\n",
    "\n",
    "    def _backward(self, x: np.array) -> None:\n",
    "        activation = x\n",
    "        for layer in reversed(self._layers):\n",
    "            activation = layer.backward_pass(da_curr=activation)\n",
    "\n",
    "    def _update(self) -> None:\n",
    "        self._optimizer.update(layers=self._layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples in the train data set\n",
    "N_TRAIN_SAMPLES = 2670\n",
    "# number of samples in the test data set\n",
    "N_TEST_SAMPLES = 500\n",
    "# number of samples in the validation data set\n",
    "N_VALID_SAMPLES = 500\n",
    "# number of classes\n",
    "N_CLASSES = 5\n",
    "# image size\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "layers = [\n",
    "    # input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    Convolution.initialize(filters=32, kernel_shape=(3, 3, 3), stride=1, padding=\"same\"),\n",
    "    # input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    ReluLayer(),\n",
    "    # input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    Convolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    # input input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    ReluLayer(),\n",
    "    # input (N, 32, 32, 32) out (N, 16, 16, 32)\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "    # input (N, 16, 16, 32) out (N, 16, 16, 32)\n",
    "    DropoutLayer(keep_prob=0.75),\n",
    "    # input (N, 16, 16, 32) out (N, 16, 16, 64)\n",
    "    Convolution.initialize(filters=64, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    # input (N, 16, 16, 64) out (N, 16, 16, 64)\n",
    "    ReluLayer(),\n",
    "    # input (N, 16, 16, 64) out (N, 16, 16, 64)\n",
    "    Convolution.initialize(filters=64, kernel_shape=(3, 3, 64), stride=1, padding=\"same\"),\n",
    "    # input (N, 16, 16, 64) out (N, 16, 16, 64)\n",
    "    ReluLayer(),\n",
    "    # input (N, 16, 16, 64) out (N, 8, 8, 64)\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "    # input  (N, 8, 8, 64) out  (N, 8, 8, 64)\n",
    "    DropoutLayer(keep_prob=0.75),\n",
    "    # input  (N, 8, 8, 64) out  (N, 8*8* 64)\n",
    "    FlattenLayer(),\n",
    "    # input (N, 8*8* 64) out (N, 256)\n",
    "    fullyConnected.initialize(units_prev=8 * 8 * 64, units_curr=256),\n",
    "    # input (N, 256) out (N, 256)\n",
    "    ReluLayer(),\n",
    "     # input (N, 256) out (N, 32)\n",
    "    fullyConnected.initialize(units_prev=256, units_curr=32),\n",
    "     # input (N, 32) out (N, 32)\n",
    "    ReluLayer(),\n",
    "     # input (N, 32) out (N, 5)\n",
    "    fullyConnected.initialize(units_prev=32, units_curr=N_CLASSES),\n",
    "     # input (N, 5) out (N, 5)\n",
    "    SoftmaxLayer()\n",
    "]\n",
    "'''\n",
    "layers = [\n",
    "    # input (N, 32, 32, 3) out (N, 32, 32, 32)\n",
    "    fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 3), stride=1, padding=\"same\"),\n",
    "    # input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    ReluLayer(),\n",
    "    # input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    # input input (N, 32, 32, 32) out (N, 32, 32, 32)\n",
    "    ReluLayer(),\n",
    "    # input (N, 32, 32, 32) out (N, 16, 16, 32)\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "   # input  (N, 16, 16, 32) out  (N, 16,16, 32),\n",
    "    DropoutLayer(keep_prob=0.85),\n",
    "    # input  (N, 16, 16, 32) out  (N, 16,16, 32),\n",
    "    fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    #input  (N, 16, 16, 32) out  (N, 16,16, 32),\n",
    "     ReluLayer(),\n",
    "    #input  (N, 16, 16, 32) out  (N, 8,8, 32),\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "    #input  (N, 8,8, 32), out  (N, 8,8, 32),\n",
    "     fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    #input  (N, 8,8, 32), out  (N, 8,8, 32),\n",
    "     ReluLayer(),\n",
    "    #input  (N, 8,8, 32), out  (N, 4,4, 32),\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "     #input  (N, 4,4, 32), out  (N, 4,4, 32),\n",
    "     DropoutLayer(keep_prob=0.85),\n",
    "    #input  (N, 4,4, 32), out  (N, 4,4, 32),\n",
    "    fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    ReluLayer(),\n",
    "    fastConvolution.initialize(filters=32, kernel_shape=(3, 3, 32), stride=1, padding=\"same\"),\n",
    "    #input  (N, 4,4, 32), out  (N, 4,4, 32),\n",
    "     ReluLayer(),\n",
    "    #input  (N, 4,4, 32), out  (N, 2,2, 32),\n",
    "    MaxPoolLayer(pool_size=(2, 2), stride=2),\n",
    "     #input (N, 2,2, 32), out  (N, 2,2, 32),\n",
    "    #DropoutLayer(keep_prob=0.7),\n",
    "     # input  (N, 2,2, 32) out  (N, 2*2* 32),\n",
    "    FlattenLayer(),\n",
    "    fullyConnected.initialize(units_prev= 2*2*32, units_curr=128),\n",
    "    ReluLayer(),\n",
    "    fullyConnected.initialize(units_prev= 128, units_curr=N_CLASSES),\n",
    "     \n",
    "     # input (N, 5) out (N, 5)\n",
    "    SoftmaxLayer()\n",
    "]\n",
    "optimizer = GradientDescent(lr=0.005)\n",
    "\n",
    "model = SequentialModel(\n",
    "    layers=layers,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 00001 | tr_loss: 0.56507 | tr_acc: 0.79513 | val_loss: 1.25636 | val_acc: 0.61400 | time: 00:01:52.62\n",
      "epoch: 00002 | tr_loss: 0.47076 | tr_acc: 0.81985 | val_loss: 1.31612 | val_acc: 0.62800 | time: 00:01:51.18\n",
      "epoch: 00003 | tr_loss: 0.49609 | tr_acc: 0.81873 | val_loss: 1.23415 | val_acc: 0.61000 | time: 00:01:51.65\n",
      "epoch: 00004 | tr_loss: 0.48431 | tr_acc: 0.82322 | val_loss: 1.51283 | val_acc: 0.61800 | time: 00:01:51.49\n",
      "epoch: 00005 | tr_loss: 0.46994 | tr_acc: 0.81948 | val_loss: 1.39453 | val_acc: 0.61000 | time: 00:01:51.36\n",
      "epoch: 00006 | tr_loss: 0.45330 | tr_acc: 0.82959 | val_loss: 1.45397 | val_acc: 0.60800 | time: 00:01:52.37\n",
      "epoch: 00007 | tr_loss: 0.48695 | tr_acc: 0.81910 | val_loss: 1.31462 | val_acc: 0.59400 | time: 00:01:48.46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4bc3fe81e698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-9f72589613dd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, y_train, x_test, y_test, epochs, bs, verbose, callback)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0my_hat_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_hat_batch\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mn_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-9f72589613dd>\u001b[0m in \u001b[0;36m_backward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda_curr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-cfe697107f2c>\u001b[0m in \u001b[0;36mbackward_pass\u001b[1;34m(self, da_curr)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0moutput_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda_curr_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         output = col2im(\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0marray_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_a_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-3e8df0e7cc63>\u001b[0m in \u001b[0;36mcol2im\u001b[1;34m(cols, array_shape, filter_dim, pad, stride)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mcols_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh_f\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mcols_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols_reshaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw_in\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    x_train=training_data, \n",
    "    y_train=training_labels, \n",
    "    x_test=validation_data, \n",
    "    y_test=validation_labels, \n",
    "    epochs=100,\n",
    "    bs=64,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_loss = model.history[\"train_loss\"]\n",
    "all_validation_loss = model.history[\"test_loss\"]\n",
    "plt.plot(all_loss ,label = 'training Loss')\n",
    "plt.plot (all_validation_loss , label='validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_accuracy:  77.6 %\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict( testing_data)\n",
    "test_acc = softmax_accuracy(test_pred, testing_labels)\n",
    "print(\"testing_accuracy: \" , test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy accuracy (CCRn): 69.00 %\n"
     ]
    }
   ],
   "source": [
    "#daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "daisy_test_pred = model.predict( daisy)\n",
    "#roses_test_acc = softmax_accuracy(roses_test_pred, roses_lbls)\n",
    "predicted_class = np.argmax(daisy_test_pred, axis=1)\n",
    "\n",
    "print ('daisy accuracy (CCRn): %.2f ' % (np.mean(predicted_class == daisy_lbls)*100) +'%')\n",
    "#print(\" Roses testing_accuracy (CCRn): \" , roses_test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dandelion accuracy (CCRn): 44.00 %\n"
     ]
    }
   ],
   "source": [
    "#daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "dandelion_test_pred = model.predict( dandelion)\n",
    "#roses_test_acc = softmax_accuracy(roses_test_pred, roses_lbls)\n",
    "predicted_class = np.argmax(dandelion_test_pred, axis=1)\n",
    "\n",
    "print ('dandelion accuracy (CCRn): %.2f ' % (np.mean(predicted_class == dandelion_lbls)*100) +'%')\n",
    "#print(\" Roses testing_accuracy (CCRn): \" , roses_test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roses accuracy (CCRn): 42.00 %\n"
     ]
    }
   ],
   "source": [
    "#daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "roses_test_pred = model.predict( roses)\n",
    "#roses_test_acc = softmax_accuracy(roses_test_pred, roses_lbls)\n",
    "predicted_class = np.argmax(roses_test_pred, axis=1)\n",
    "\n",
    "print ('Roses accuracy (CCRn): %.2f ' % (np.mean(predicted_class == roses_lbls)*100) +'%')\n",
    "#print(\" Roses testing_accuracy (CCRn): \" , roses_test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunflowers accuracy (CCRn): 74.00 %\n"
     ]
    }
   ],
   "source": [
    "#daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "sunflowers_test_pred = model.predict( sunflowers)\n",
    "#roses_test_acc = softmax_accuracy(roses_test_pred, roses_lbls)\n",
    "predicted_class = np.argmax(sunflowers_test_pred, axis=1)\n",
    "\n",
    "print ('sunflowers accuracy (CCRn): %.2f ' % (np.mean(predicted_class == sunflowers_lbls)*100) +'%')\n",
    "#print(\" Roses testing_accuracy (CCRn): \" , roses_test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tulips accuracy (CCRn): 60.00 %\n"
     ]
    }
   ],
   "source": [
    "#daisy,dandelion,roses,sunflowers,tulips = np.split(testing_data,5)\n",
    "#daisy_lbls,dandelion_lbls,roses_lbls,sunflowers_lbls,tulips_lbls=np.split(testing_labels,5)\n",
    "tulips_test_pred = model.predict( tulips)\n",
    "#roses_test_acc = softmax_accuracy(roses_test_pred, roses_lbls)\n",
    "predicted_class = np.argmax(tulips_test_pred, axis=1)\n",
    "\n",
    "print ('tulips accuracy (CCRn): %.2f ' % (np.mean(predicted_class == tulips_lbls)*100) +'%')\n",
    "#print(\" Roses testing_accuracy (CCRn): \" , roses_test_acc * 100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
